{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Clasificación en Beta Bank "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El banco Beta Bank está perdiendo clientes cada mes. Al parecer, se ha descubierto que es mucho más barato salvar a los clientes ya existentes del banco que atraer a nuevos.\n",
    "\n",
    "Por lo tanto, se necesita realizar un modelo que prediga si un cliente dejará el banco pronto. Dentro de la información que se poseé son los datos sobre el comportamiento pasado de los clientes y la terminación de contratos con el banco. Esto se detallará más adelante todas las variables con las que se cuenta. \n",
    "\n",
    "El objetivo de este proyecto es crear un modelo con el máximo valor *F1* posible. Para aprobar la revisión, se necesita un valor *F1* de al menos 0.59. Se puede verificar *F1* para el conjunto de prueba. \n",
    "\n",
    "Adicional, se debe medir la métrica *AUC-ROC* y compararla con el valor *F1*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Información-general-del-estudio\" data-toc-modified-id=\"Información-general-del-estudio-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Información general del estudio</a></span></li><li><span><a href=\"#Inicialización\" data-toc-modified-id=\"Inicialización-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Inicialización</a></span><ul class=\"toc-item\"><li><span><a href=\"#Librerías\" data-toc-modified-id=\"Librerías-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Librerías</a></span></li><li><span><a href=\"#Cargar-los-datos\" data-toc-modified-id=\"Cargar-los-datos-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Cargar los datos</a></span></li><li><span><a href=\"#Estudio-de-información-general\" data-toc-modified-id=\"Estudio-de-información-general-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Estudio de información general</a></span></li></ul></li><li><span><a href=\"#Preparar-los-datos\" data-toc-modified-id=\"Preparar-los-datos-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preparar los datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Nombres-de-columnas-a-minúsculas\" data-toc-modified-id=\"Nombres-de-columnas-a-minúsculas-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Nombres de columnas a minúsculas</a></span></li><li><span><a href=\"#Análisis-y-tratamiento-de-valores-ausentes\" data-toc-modified-id=\"Análisis-y-tratamiento-de-valores-ausentes-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Análisis y tratamiento de valores ausentes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Análisis-de-valores-por-columna\" data-toc-modified-id=\"Análisis-de-valores-por-columna-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Análisis de valores por columna</a></span><ul class=\"toc-item\"><li><span><a href=\"#Análisis-tenure\" data-toc-modified-id=\"Análisis-tenure-3.2.1.1\"><span class=\"toc-item-num\">3.2.1.1&nbsp;&nbsp;</span>Análisis <code>tenure</code></a></span></li></ul></li></ul></li><li><span><a href=\"#Conversión-tipos-de-datos\" data-toc-modified-id=\"Conversión-tipos-de-datos-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Conversión tipos de datos</a></span></li></ul></li><li><span><a href=\"#Implementación-de-modelo-(clases-desbalanceadas)\" data-toc-modified-id=\"Implementación-de-modelo-(clases-desbalanceadas)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Implementación de modelo (clases desbalanceadas)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Segmentación-features-y-target\" data-toc-modified-id=\"Segmentación-features-y-target-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Segmentación <code>features</code> y <code>target</code></a></span></li><li><span><a href=\"#Verificación-equilibrio-clase-objetivo\" data-toc-modified-id=\"Verificación-equilibrio-clase-objetivo-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Verificación equilibrio clase objetivo</a></span></li><li><span><a href=\"#División-de-conjuntos-de-datos\" data-toc-modified-id=\"División-de-conjuntos-de-datos-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>División de conjuntos de datos</a></span></li><li><span><a href=\"#Implementación-de-modelo-en-datos-de-entrenamiento-y-validación\" data-toc-modified-id=\"Implementación-de-modelo-en-datos-de-entrenamiento-y-validación-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Implementación de modelo en datos de entrenamiento y validación</a></span><ul class=\"toc-item\"><li><span><a href=\"#Árbol-de-decisión\" data-toc-modified-id=\"Árbol-de-decisión-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Árbol de decisión</a></span><ul class=\"toc-item\"><li><span><a href=\"#Verificación-de-hiperparámetros\" data-toc-modified-id=\"Verificación-de-hiperparámetros-4.4.1.1\"><span class=\"toc-item-num\">4.4.1.1&nbsp;&nbsp;</span>Verificación de hiperparámetros</a></span></li><li><span><a href=\"#Implementación-datos-de-prueba\" data-toc-modified-id=\"Implementación-datos-de-prueba-4.4.1.2\"><span class=\"toc-item-num\">4.4.1.2&nbsp;&nbsp;</span>Implementación datos de prueba</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Implementación-de-modelo-(clases-balanceadas)\" data-toc-modified-id=\"Implementación-de-modelo-(clases-balanceadas)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Implementación de modelo (clases balanceadas)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Balanceo-de-clases\" data-toc-modified-id=\"Balanceo-de-clases-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Balanceo de clases</a></span></li><li><span><a href=\"#Verificación-de-equilibrio-de-clase-objetivo\" data-toc-modified-id=\"Verificación-de-equilibrio-de-clase-objetivo-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Verificación de equilibrio de clase objetivo</a></span></li><li><span><a href=\"#Implementación-de-modelo-en-datos-de-entrenamiento\" data-toc-modified-id=\"Implementación-de-modelo-en-datos-de-entrenamiento-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Implementación de modelo en datos de entrenamiento</a></span><ul class=\"toc-item\"><li><span><a href=\"#Árbol-de-decisión\" data-toc-modified-id=\"Árbol-de-decisión-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>Árbol de decisión</a></span><ul class=\"toc-item\"><li><span><a href=\"#Verificación-de-hiperparámetros\" data-toc-modified-id=\"Verificación-de-hiperparámetros-5.3.1.1\"><span class=\"toc-item-num\">5.3.1.1&nbsp;&nbsp;</span>Verificación de hiperparámetros</a></span></li><li><span><a href=\"#Implementación-datos-de-prueba\" data-toc-modified-id=\"Implementación-datos-de-prueba-5.3.1.2\"><span class=\"toc-item-num\">5.3.1.2&nbsp;&nbsp;</span>Implementación datos de prueba</a></span></li></ul></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-5.3.2\"><span class=\"toc-item-num\">5.3.2&nbsp;&nbsp;</span>Random Forest</a></span><ul class=\"toc-item\"><li><span><a href=\"#Verificación-de-hiperparámetros\" data-toc-modified-id=\"Verificación-de-hiperparámetros-5.3.2.1\"><span class=\"toc-item-num\">5.3.2.1&nbsp;&nbsp;</span>Verificación de hiperparámetros</a></span></li><li><span><a href=\"#Implementación-datos-de-prueba\" data-toc-modified-id=\"Implementación-datos-de-prueba-5.3.2.2\"><span class=\"toc-item-num\">5.3.2.2&nbsp;&nbsp;</span>Implementación datos de prueba</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusiones</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información general del estudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se indica las variables y sus características: \n",
    "\n",
    "- `RowNumber` — índice de cadena de datos\n",
    "- `CustomerId` — identificador de cliente único\n",
    "- `Surname` — apellido\n",
    "- `CreditScore` — valor de crédito\n",
    "- `Geography` — país de residencia\n",
    "- `Gender` — sexo\n",
    "- `Age` — edad\n",
    "- `Tenure` — período durante el cual ha madurado el depósito a plazo fijo de un cliente (años).\n",
    "- `Balance` — saldo de la cuenta\n",
    "- `NumOfProducts` — número de productos bancarios utilizados por el cliente\n",
    "- `HasCrCard` — el cliente tiene una tarjeta de crédito (`Sí` - `1`, `No` - `0`)\n",
    "- `IsActiveMember` — actividad del cliente (`Sí` - `1`, `No` - `0`)\n",
    "- `EstimatedSalary` — salario estimado\n",
    "\n",
    "Variable objetivo:\n",
    "- `Exited` — el cliente se ha ido (`Sí` - `1`, `No` - `0`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, se utilizarán todas estas variables, junto con el historial de varios clientes que ya se han ido a otros bancos, para poder predecir si otros clientes se van a ir o no. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalación de la librería `imbalanced-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 21.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (0.24.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6 MB 62.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn) (3.1.0)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 47.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from imbalanced-learn) (1.21.1)\n",
      "Installing collected packages: joblib, scikit-learn, imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.10.1 joblib-1.2.0 scikit-learn-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -U imbalanced-learn scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inicia cargando todas las librerías de Python que se utilizarán a lo largo del proyecto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar todas las librerías\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, recall_score, precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from itertools import product\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga los datos de los diferentes archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga del archivo en DataFrame\n",
    "data_bank = pd.read_csv(\"/datasets/Churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estudio de información general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos a revisar el contenido del archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of 'data_bank': Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
      "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
      "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
      "      dtype='object')\n",
      "\n",
      "Rows and columns of 'data_bank': (10000, 14)\n"
     ]
    }
   ],
   "source": [
    "# nombre columnas\n",
    "print(\"Columns of 'data_bank':\", data_bank.columns)\n",
    "# número filas x columnas\n",
    "print(\"\")\n",
    "print(\"Rows and columns of 'data_bank':\", data_bank.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha comprobado la información que nos entregaron en un inicio, el cual tenemos un dataset que lo llamamos `data_bank`, que tiene 14 columnas (que fueron descritas en la sección 1.) y un total de 10,000 datos. Verifiquemos cómo están los datos, si hay que realizar o no alguna limpieza en los datos. \n",
    "\n",
    "Visualicemos la información inicial y una información resumida de la tabla `data_bank`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# revisión datos iniciales, tipos de datos\n",
    "display(data_bank.head())\n",
    "print(\"\")\n",
    "print(data_bank.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según la información que tenemos, y lo que estamos visualizando, no tenemos un dataset completamente limpio. Por ejemplo, la variable `Tenure`, que significa la cantidad de tiempo (en años) que ha pasado desde que un cliente del banco hizo un depósito a plazo fijo hasta que dicho depósito alcanzó su fecha de vencimiento, tiene valores ausentes. De igual forma, algunas variables no están convertidas en los tipos de datos correctos. \n",
    "\n",
    "Es importante preparar los datos de forma correcta para poder realizar un análisis previo a los datos y después aplicar el modelo de clasificación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombres de columnas a minúsculas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mantener una mejor estructura y presentación en el análisis de datos, se reemplazará los nombres de las columnas `data_bank` a minúsculas, aplicando también el método `snake_case` donde las varibales van a estar separadas por guión bajo (`_`) en vez de que todo esté unido, para poder entender mejor.\n",
    "\n",
    "Para esto, se define la siguiente función, utilizando la biblioteca `re` (expresiones regulares) para ayudar mejor en la conversión. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para convertir variables a snake_case\n",
    "def to_snake_case(name):\n",
    "    # inserta guion bajo antes de cada letra mayúscula y convierte la letra a minúscula\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    # inserta guion bajo entre una letra minúscula y una letra mayúscula y convierte la letra a minúscula\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta función, aplicamos a todas las columnas de `data_bank`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_number', 'customer_id', 'surname', 'credit_score', 'geography',\n",
      "       'gender', 'age', 'tenure', 'balance', 'num_of_products', 'has_cr_card',\n",
      "       'is_active_member', 'estimated_salary', 'exited'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# convierte los nombres de las columnas a snake_case\n",
    "snake_case_column_names = [to_snake_case(name) for name in data_bank.columns]\n",
    "\n",
    "# aplica los nombres de las columnas convertidos al DataFrame\n",
    "data_bank.columns = snake_case_column_names\n",
    "\n",
    "# verificamos\n",
    "print(data_bank.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos cambiado los nombres de las columnas de forma correcta. Ahora, vamos a proceder con el análisis de los valores ausentes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis y tratamiento de valores ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de convertir los tipos de datos, verifiquemos qué datos hay en cada columna junto con sus valores ausentes. Esto es importante para no obtener un error por tener valores ausentes o valores infinitos en las filas de las columnas al momento de cambiar el tipo de dato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tenure'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificación columnas con valores ausentes\n",
    "data_bank.columns[data_bank.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como indicamos anteriormente, solo contamos con valores ausentes en `ternure`. \n",
    "\n",
    "Comprobemos cuántos valores ausentes tenemos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_number            0\n",
       "customer_id           0\n",
       "surname               0\n",
       "credit_score          0\n",
       "geography             0\n",
       "gender                0\n",
       "age                   0\n",
       "tenure              909\n",
       "balance               0\n",
       "num_of_products       0\n",
       "has_cr_card           0\n",
       "is_active_member      0\n",
       "estimated_salary      0\n",
       "exited                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# número de valores ausentes por columna\n",
    "data_bank.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En total tenemos 909 valores ausentes en la variable `ternure`. Ahora verifiquemos qué porcentaje representa en relación al total de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_number - 0.0%\n",
      "customer_id - 0.0%\n",
      "surname - 0.0%\n",
      "credit_score - 0.0%\n",
      "geography - 0.0%\n",
      "gender - 0.0%\n",
      "age - 0.0%\n",
      "tenure - 9.09%\n",
      "balance - 0.0%\n",
      "num_of_products - 0.0%\n",
      "has_cr_card - 0.0%\n",
      "is_active_member - 0.0%\n",
      "estimated_salary - 0.0%\n",
      "exited - 0.0%\n"
     ]
    }
   ],
   "source": [
    "# % de missing values por columna\n",
    "for col in data_bank.columns:\n",
    "    pct_missing = np.mean(data_bank[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores ausentes de la columna `tenure` representan 9.09% de los datos totales. Este valor es menos del 10%, aún así, es un valor alto que hay que considerar qué realizar con estos valores ausentes. \n",
    "\n",
    "Para entender mejor esto, es importante revisar cómo está la distribución de los datos de cada columna, y qué datos hay. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de valores por columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se realizar un análisis de la frecuencia de datos de cada columna: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frecuencia de categorías para columna: row_number\n",
      "2049    1\n",
      "8865    1\n",
      "6806    1\n",
      "4759    1\n",
      "8857    1\n",
      "2716    1\n",
      "669     1\n",
      "6814    1\n",
      "4767    1\n",
      "2724    1\n",
      "Name: row_number, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: customer_id\n",
      "15695872    1\n",
      "15801062    1\n",
      "15682268    1\n",
      "15647453    1\n",
      "15684319    1\n",
      "15641312    1\n",
      "15639265    1\n",
      "15743714    1\n",
      "15649508    1\n",
      "15621550    1\n",
      "Name: customer_id, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: surname\n",
      "Smith       32\n",
      "Martin      29\n",
      "Scott       29\n",
      "Walker      28\n",
      "Brown       26\n",
      "Yeh         25\n",
      "Genovese    25\n",
      "Shih        25\n",
      "Wright      24\n",
      "Maclean     24\n",
      "Name: surname, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: credit_score\n",
      "850    233\n",
      "678     63\n",
      "655     54\n",
      "667     53\n",
      "705     53\n",
      "684     52\n",
      "651     50\n",
      "670     50\n",
      "683     48\n",
      "648     48\n",
      "Name: credit_score, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: geography\n",
      "France     5014\n",
      "Germany    2509\n",
      "Spain      2477\n",
      "Name: geography, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: gender\n",
      "Male      5457\n",
      "Female    4543\n",
      "Name: gender, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: age\n",
      "37    478\n",
      "38    477\n",
      "35    474\n",
      "36    456\n",
      "34    447\n",
      "33    442\n",
      "40    432\n",
      "39    423\n",
      "32    418\n",
      "31    404\n",
      "Name: age, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: tenure\n",
      "1.0     952\n",
      "2.0     950\n",
      "8.0     933\n",
      "3.0     928\n",
      "5.0     927\n",
      "7.0     925\n",
      "4.0     885\n",
      "9.0     882\n",
      "6.0     881\n",
      "10.0    446\n",
      "Name: tenure, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: balance\n",
      "0.00         3617\n",
      "105473.74       2\n",
      "130170.82       2\n",
      "72594.00        1\n",
      "139723.90       1\n",
      "110112.54       1\n",
      "137367.94       1\n",
      "101238.24       1\n",
      "149887.49       1\n",
      "123105.88       1\n",
      "Name: balance, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: num_of_products\n",
      "1    5084\n",
      "2    4590\n",
      "3     266\n",
      "4      60\n",
      "Name: num_of_products, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: has_cr_card\n",
      "1    7055\n",
      "0    2945\n",
      "Name: has_cr_card, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: is_active_member\n",
      "1    5151\n",
      "0    4849\n",
      "Name: is_active_member, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: estimated_salary\n",
      "24924.92     2\n",
      "109145.20    1\n",
      "59755.14     1\n",
      "1557.82      1\n",
      "117202.19    1\n",
      "195333.98    1\n",
      "181208.47    1\n",
      "83473.82     1\n",
      "71095.41     1\n",
      "65413.41     1\n",
      "Name: estimated_salary, dtype: int64\n",
      "\n",
      "Frecuencia de categorías para columna: exited\n",
      "0    7963\n",
      "1    2037\n",
      "Name: exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# frecuencia de datos repetidos por columna en data_bank\n",
    "for col in data_bank.columns:\n",
    "    print ('\\nFrecuencia de categorías para columna: %s'%col)\n",
    "    print (data_bank[col].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la distribución de los datos, hemos descubierto información importante en cada una de las columnas, aunque hemos visto un primer vistazo, ya que máximo visualizamos los primeros 10 datos que se repiten. \n",
    "\n",
    "Por el momento, la columna que más nos importa analizar es `tenure`, por lo que vamos a analizarla con más detalle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análisis `tenure`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos con más detalle la variable `tenure`. Para esto, volvemos a aplicar el método `value_counts` pero verificando los valores nulos, para ver cuántos son: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     952\n",
       "2.0     950\n",
       "8.0     933\n",
       "3.0     928\n",
       "5.0     927\n",
       "7.0     925\n",
       "NaN     909\n",
       "4.0     885\n",
       "9.0     882\n",
       "6.0     881\n",
       "10.0    446\n",
       "0.0     382\n",
       "Name: tenure, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribución de los datos de tenure\n",
    "data_bank[\"tenure\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer tenemos valores ausentes por un problema de información, de recopilación de datos o inconsistencias en el registro. Sea cual sea la razón, vamos a tener que tomar una decisión sobre qué hacer con estos valores ausentes, ya que al momento de aplicar un modelo de machine learning, no puede haber valores nulos. \n",
    "\n",
    "En un inicio se pensaba que los valores ausentes podían ser datos con 0.0, sin embargo, si tenemos una categoría con ese valor. Por esta razón, se procede a imputar los datos mediante la moda, pero en base a 4 categorías que creemos que son las que más afectan a la variable `tenure` que son: `geography`, `age`, `num_of_products` y  `is_active_member`.\n",
    "\n",
    "Las razones son las siguientes: \n",
    "- `geography`: es posible que la duración de los depósitos a plazo fijo varíe según el país de residencia.\n",
    "- `age`: la edad del cliente podría estar relacionada con la duración de los depósitos a plazo fijo, ya que diferentes grupos de edad pueden tener diferentes hábitos de ahorro e inversión.\n",
    "- `num_of_products`: la cantidad de productos bancarios utilizados puede estar relacionada con la duración de depósitos a plazo fijo.\n",
    "- `is_active_member`: los clientes más activos podrían tener diferentes preferencias de duración de depósitos a plazo fijo en comparación con los menos activos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a esta información, procedemos a crear la siguiente función `fill_tenure_na`, el cual calcula la moda de la columna `tenure`, donde si la moda no está vacía, reemplaza los valores `NaN` en la columna con la moda, y en cambio, si está vacía, se devuelve la información de `tenure`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función fill_tenure_na\n",
    "def fill_tenure_na(group):\n",
    "    mode = group[\"tenure\"].mode()\n",
    "    if not mode.empty:\n",
    "        return group[\"tenure\"].fillna(mode.iloc[0])\n",
    "    else:\n",
    "        return group[\"tenure\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo, ahora calculemos la moda global de la columna `tenure`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moda global de 'tenure'\n",
    "global_mode = data_bank[\"tenure\"].mode().iloc[0]\n",
    "global_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, procedemos a realizar una agrupación con las 4 variables mencionadas anteriormente. La idea con esta agrupación es utilizar para aplicar en la función que creamos `fill_tenure_na` en cada grupo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupación por 'geography', 'age', 'num_of_products' y 'is_active_member'\n",
    "grouped = data_bank.groupby([\"geography\", \"age\", \"num_of_products\", \"is_active_member\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos la función `fill_tenure_na` en base a la agrupación `grouped`, y reseteamos el índice para eliminar el índice jerárquico que se creó por el `groupby`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_number</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>surname</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>7.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_number  customer_id   surname  credit_score geography  gender  age  \\\n",
       "0           1     15634602  Hargrave           619    France  Female   42   \n",
       "1           2     15647311      Hill           608     Spain  Female   41   \n",
       "2           3     15619304      Onio           502    France  Female   42   \n",
       "3           4     15701354      Boni           699    France  Female   39   \n",
       "4           5     15737888  Mitchell           850     Spain  Female   43   \n",
       "\n",
       "   tenure    balance  num_of_products  has_cr_card  is_active_member  \\\n",
       "0     2.0       0.00                1            1                 1   \n",
       "1     2.0   83807.86                1            0                 1   \n",
       "2     7.0  159660.80                3            1                 0   \n",
       "3    10.0       0.00                2            0                 0   \n",
       "4     4.0  125510.82                1            1                 1   \n",
       "\n",
       "   estimated_salary  exited  \n",
       "0         101348.88       1  \n",
       "1         112542.58       0  \n",
       "2         113931.57       1  \n",
       "3          93826.63       0  \n",
       "4          79084.10       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cálculo de la moda de 'tenure' para cada grupo y se reemplaza los valores ausentes\n",
    "data_bank[\"tenure\"] = grouped.apply(fill_tenure_na).reset_index(drop=True)\n",
    "data_bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfecto, ahora comprobamos si tenemos aún valores ausentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# verificación valores ausentes\n",
    "print(data_bank[\"tenure\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente, tenemos aún 17 valores asuentes, por lo que procedemos a reemplazar con la moda global: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellena cualquier valor ausente restante con la moda global\n",
    "data_bank[\"tenure\"].fillna(global_mode, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y volvemos a comprobar: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# verificación valores ausentes\n",
    "print(data_bank[\"tenure\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo, ahora veamos nuevamente la distribución de los datos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     1139\n",
       "2.0     1085\n",
       "3.0     1033\n",
       "7.0     1007\n",
       "8.0     1001\n",
       "5.0      995\n",
       "6.0      978\n",
       "4.0      969\n",
       "9.0      940\n",
       "10.0     450\n",
       "0.0      403\n",
       "Name: tenure, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribución de los datos de tenure\n",
    "data_bank[\"tenure\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nivel general, se cambió el valor de todas las categorías de los años del plazo fijo, lo cual nos indica que si se pudo reempalzar de forma los valores porque se tomó en cuenta la información de 4 categorías y no solo de una o dos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversión tipos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo, ahora en base a la información que vimos en la sección `3.2.1`, es decir, qué datos tenemos en cada columna, procedemos a realizar los siguientes cambios de tipos de datos: \n",
    "\n",
    "- `customer_id`: como es un identificador, debe estar como un tipo de dato `str`.\n",
    "- `tenure`: como son años, y no se tiene decimales, es mejor manejarlo como `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversión tipos de datos\n",
    "data_bank['customer_id'] = data_bank['customer_id'].astype(str)\n",
    "data_bank['tenure'] = data_bank['tenure'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, creemos que la columna `row_number` no aportará en nuestro análisis posterior ya que es el índice o registro desde 1 hasta 10,000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar columna \n",
    "data_bank = data_bank.drop('row_number', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, nuestros datos quedarían de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customer_id       10000 non-null  object \n",
      " 1   surname           10000 non-null  object \n",
      " 2   credit_score      10000 non-null  int64  \n",
      " 3   geography         10000 non-null  object \n",
      " 4   gender            10000 non-null  object \n",
      " 5   age               10000 non-null  int64  \n",
      " 6   tenure            10000 non-null  int64  \n",
      " 7   balance           10000 non-null  float64\n",
      " 8   num_of_products   10000 non-null  int64  \n",
      " 9   has_cr_card       10000 non-null  int64  \n",
      " 10  is_active_member  10000 non-null  int64  \n",
      " 11  estimated_salary  10000 non-null  float64\n",
      " 12  exited            10000 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 1015.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# información general\n",
    "data_bank.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>surname</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id   surname  credit_score geography  gender  age  tenure  \\\n",
       "0    15634602  Hargrave           619    France  Female   42       2   \n",
       "1    15647311      Hill           608     Spain  Female   41       2   \n",
       "2    15619304      Onio           502    France  Female   42       7   \n",
       "3    15701354      Boni           699    France  Female   39      10   \n",
       "4    15737888  Mitchell           850     Spain  Female   43       4   \n",
       "\n",
       "     balance  num_of_products  has_cr_card  is_active_member  \\\n",
       "0       0.00                1            1                 1   \n",
       "1   83807.86                1            0                 1   \n",
       "2  159660.80                3            1                 0   \n",
       "3       0.00                2            0                 0   \n",
       "4  125510.82                1            1                 1   \n",
       "\n",
       "   estimated_salary  exited  \n",
       "0         101348.88       1  \n",
       "1         112542.58       0  \n",
       "2         113931.57       1  \n",
       "3          93826.63       0  \n",
       "4          79084.10       0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vistazo primeras columnas\n",
    "data_bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de modelo (clases desbalanceadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo, ahora que está listo nuestros datos, podemos realizar el análisis con la implementación de uno o más modelos de clasificación. Para esto, primero hay que trabajar en la segmentación del conjunto de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentación `features` y `target`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder implementar cualquier modelo de machine learning, debemos separar las variables entre características (`features`) y objetivo (`target`), donde nuestra variable objetivo será `exited`, ya que es la variable que vamos a categorizar en base a la información que tenemos. \n",
    "\n",
    "Sin embargo, analizando a fondo, las variables `customer_id` y `surname` no van a agregar ningún valor o análisis al momento de implementar los modelos. Por esta razón, también se quitará estas columnas en la variable `features`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# declarar features y target\n",
    "features = data_bank.drop([\"exited\", \"customer_id\", \"surname\"], axis=1)\n",
    "target = data_bank[\"exited\"]\n",
    "\n",
    "# comprobamos\n",
    "print(features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación podemos ver un resumen de las variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resumen\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score geography  gender  age  tenure    balance  num_of_products  \\\n",
       "0           619    France  Female   42       2       0.00                1   \n",
       "1           608     Spain  Female   41       2   83807.86                1   \n",
       "2           502    France  Female   42       7  159660.80                3   \n",
       "3           699    France  Female   39      10       0.00                2   \n",
       "4           850     Spain  Female   43       4  125510.82                1   \n",
       "\n",
       "   has_cr_card  is_active_member  estimated_salary  \n",
       "0            1                 1         101348.88  \n",
       "1            0                 1         112542.58  \n",
       "2            1                 0         113931.57  \n",
       "3            0                 0          93826.63  \n",
       "4            1                 1          79084.10  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resumen\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según la información que analizamos en las columnas `geography` y `gender`, en cada una de las columnas tenemos 3 y 2 categorías respectivamente. Como vamos a aplicar modelos de aprendizaje supervisado, muchos de estos modelos no pueden manejar directamente variables categóricas. \n",
    "\n",
    "Por lo tanto, debemos aplicar el método de One-Hot Encoding el cual las variables se convierten en representaciones numéricas donde el modelo puede entender y procesar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicación de one-hot enconding en geography y gender\n",
    "features = pd.get_dummies(features, columns=[\"geography\", \"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>geography_France</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score  age  tenure    balance  num_of_products  has_cr_card  \\\n",
       "0           619   42       2       0.00                1            1   \n",
       "1           608   41       2   83807.86                1            0   \n",
       "2           502   42       7  159660.80                3            1   \n",
       "3           699   39      10       0.00                2            0   \n",
       "4           850   43       4  125510.82                1            1   \n",
       "\n",
       "   is_active_member  estimated_salary  geography_France  geography_Germany  \\\n",
       "0                 1         101348.88                 1                  0   \n",
       "1                 1         112542.58                 0                  0   \n",
       "2                 0         113931.57                 1                  0   \n",
       "3                 0          93826.63                 1                  0   \n",
       "4                 1          79084.10                 0                  0   \n",
       "\n",
       "   geography_Spain  gender_Female  gender_Male  \n",
       "0                0              1            0  \n",
       "1                1              1            0  \n",
       "2                0              1            0  \n",
       "3                0              1            0  \n",
       "4                1              1            0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos la información\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación equilibrio clase objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo, ahora que tenemos la información separada, verifiquemos qué tan equilibrado está nuestra clase objetivo. Para esto, vamos a contar el total de datos que tenemos y obtener el porcentaje. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidades de cada clase:\n",
      "0    7963\n",
      "1    2037\n",
      "Name: exited, dtype: int64\n",
      "\n",
      "Porcentajes de cada clase:\n",
      "0    79.63\n",
      "1    20.37\n",
      "Name: exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# conteo de clases\n",
    "class_counts = target.value_counts()\n",
    "# porcentajes\n",
    "class_percentages = class_counts / len(target) * 100\n",
    "# imprimimos\n",
    "print(\"Cantidades de cada clase:\")\n",
    "print(class_counts)\n",
    "print(\"\\nPorcentajes de cada clase:\")\n",
    "print(class_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer si tenemos la clase desbalanceada, ya que la mayoría de los clientes aún no han dejado el banco (`0`) pero un 20% si lo ha dejado (`1`). \n",
    "\n",
    "Por el momento no vamos a equilibrar las clases, ya que queremos qué resultados obtenemos con clases desequilibradas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de conjuntos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a dividir nuestra fuente de datos en conjunto de entrenamiento, de validación y de prueba. De esta forma nos aseguramos a mantener una cierta calidad en el modelo, y cuando implementemos, no sepa todas las respuestas antes de aprender el conjunto de entrenamiento. \n",
    "\n",
    "Como no tenemos un conjunto de prueba, vamos a dividir nuestra fuente de datos en 3:1:1 (60% datos de entrenamiento, 20% datos de validación y 20% datos de prueba). \n",
    "\n",
    "Con el dataset de validación ayudará a identificar modelos sobreajustados, y con el conjunto de prueba nos ayudará para una evaluación final del modelo entrenado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se divide primero en conjunto de entrenamiento_validacion y prueba\n",
    "features_train_val, features_test, target_train_val, target_test = train_test_split(features, target, test_size=0.2, random_state=4299)\n",
    "\n",
    "# Luego, se divide el conjunto de entrenamiento_validacion en entrenamiento y validación\n",
    "features_train, features_val, target_train, target_val = train_test_split(features_train_val, target_train_val, test_size=0.25, random_state=4299)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, comprobamos que nuestro dataset esté separado correctamente: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 6000\n",
      "Tamaño del conjunto de validación: 2000\n",
      "Tamaño del conjunto de prueba: 2000\n"
     ]
    }
   ],
   "source": [
    "# impresión del tamaño de los conjuntos de datos\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(features_train))\n",
    "print(\"Tamaño del conjunto de validación:\", len(features_val))\n",
    "print(\"Tamaño del conjunto de prueba:\", len(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporción del conjunto de entrenamiento: 0.6\n",
      "Proporción del conjunto de validación: 0.2\n",
      "Proporción del conjunto de prueba: 0.2\n",
      "Total: 1.0\n"
     ]
    }
   ],
   "source": [
    "# verificación distribución de datos\n",
    "total = len(features)\n",
    "train_ratio = len(features_train) / total\n",
    "val_ratio = len(features_val) / total\n",
    "test_ratio = len(features_test) / total\n",
    "\n",
    "print(\"Proporción del conjunto de entrenamiento:\", train_ratio)\n",
    "print(\"Proporción del conjunto de validación:\", val_ratio)\n",
    "print(\"Proporción del conjunto de prueba:\", test_ratio)\n",
    "print(\"Total:\", train_ratio + val_ratio + test_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfecto, el dataset está dividido de forma correcta en entrenamiento (60%), validación (20%) y prueba (20%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de modelo en datos de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos correctamente los datos, podemos investigar qué modelo se ajusta mejor a nuestros datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Árbol de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificación de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a empezar con el modelo del árbol de decisión. \n",
    "\n",
    "A continuación, se utilizará un for loop que ayudará a verificar qué hiperparámetro es mejor al momento de aplicar el árbol de decisión, con una máxima profundidad de 50. A partir de esto, obtendremos el `accuracy_score` que se utiliza específicamente en problemas de clasificación para evaluar la precisión del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mejor puntuación de exactitud del conjunto de validación (max_depth = 6): 0.867\n"
     ]
    }
   ],
   "source": [
    "# variables iniciales\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "\n",
    "# for loop para árbol de decisión con mejor hiperparámetro\n",
    "for depth in range(1, 51):\n",
    "        # aplicamos el modelo de árbol de decisión con distintos hiperparámetros\n",
    "        model = DecisionTreeClassifier(max_depth=depth, random_state=4299)\n",
    "        \n",
    "        # entrenamos el modelo con el conjunto de entrenamiento\n",
    "        model.fit(features_train, target_train)\n",
    "        \n",
    "        # predicciones con el conjunto de validación\n",
    "        predictions_valid = model.predict(features_val) \n",
    "\n",
    "        # precisión\n",
    "        result = accuracy_score(target_val, predictions_valid)\n",
    "        \n",
    "        # mejor resultado\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_depth = depth\n",
    "            \n",
    "print(f\"La mejor puntuación de exactitud del conjunto de validación (max_depth = {best_depth}): {best_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de Árbol de decisión llega a un umbral de exactitud de 0.867 con una profundidad máxima de 6, siendo una buen resultado. \n",
    "\n",
    "Por lo tanto, podríamos decir que el árbol de decisión con el hiperparámetro `max_depth = 6` nos ayudará a predecir de forma correcta si un cliente se a va ir del banco o no.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementación datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementemos el modelo del árbol de decisión con un `max_depth` igual a 6 en los datos de prueba, calculando el `accuracy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de prueba (max_depth = 6): 0.8635\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo con el conjunto de entrenamiento y validación\n",
    "model = DecisionTreeClassifier(max_depth=6, random_state=4299)\n",
    "model.fit(features_train_val, target_train_val)\n",
    "\n",
    "# Predecimos las etiquetas para el conjunto de prueba\n",
    "predictions_test = model.predict(features_test)\n",
    "\n",
    "# Calculamos la precisión en el conjunto de prueba\n",
    "accuracy = accuracy_score(target_test, predictions_test)\n",
    "\n",
    "print(f\"Precisión en el conjunto de prueba (max_depth = 6): {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos de prueba, llegamos a una precisión del 0.8635, siendo bastante alto. Este parámetro mide la proporción de instancias clasificadas correctamente en relación con el total de instancias. Hay que tomar en cuenta que esta métrica no siempre es la mejor cuando las clases están desequilibradas. \n",
    "\n",
    "Es importante calcular las distintas métricas para poder obtener mejores conclusiones, por ejemplo la matriz de confusión: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[1549   59]\n",
      " [ 214  178]]\n"
     ]
    }
   ],
   "source": [
    "# cálculo matriz de confusión\n",
    "conf_matrix = confusion_matrix(target_test, predictions_test)\n",
    "\n",
    "# impresión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión con los datos obtenidos representan lo siguiente: \n",
    "- 1549 (TN): Verdaderos negativos - El número de clientes que realmente NO abandonaron el banco (clase 0) y fueron clasificados correctamente como NO abandonadores por el modelo.\n",
    "- 59 (FP): Falsos positivos - El número de clientes que realmente NO abandonaron el banco (clase 0) pero fueron clasificados incorrectamente como abandonadores (clase 1) por el modelo, lo cual se equivocó en 59 clientes. \n",
    "- 214 (FN): Falsos negativos - El número de clientes que realmente abandonaron el banco (clase 1) pero fueron clasificados incorrectamente como NO abandonadores (clase 0) por el modelo, lo cual se equivocó en 214 clientes.\n",
    "- 178 (TP): Verdaderos positivos - El número de clientes que realmente abandonaron el banco (clase 1) y fueron clasificados correctamente como abandonadores por el modelo.\n",
    "\n",
    "Según esta información, lo que realmente nos interesa saber es qué tan bueno el modelo permite clasificar de forma correcta los clientes que van a abandonar el banco (clase 1), por lo tanto, 214 clientes no pudo identificarlos bien. Aquí es el problema de tener desbalanceado las clases, por lo que es importante mejorar esto para la próxima. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para tener todo más claro, calcularemos las siguientes métricas, `recall` y `precision`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.7510548523206751\n",
      "Recall: 0.45408163265306123\n"
     ]
    }
   ],
   "source": [
    "# Calcular precision_score\n",
    "precision = precision_score(target_test, predictions_test)\n",
    "\n",
    "# Calcular recall_score\n",
    "recall = recall_score(target_test, predictions_test)\n",
    "\n",
    "print(f\"Precisión: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos obtenido una precisión del 0.7510, esto quiere decir que el modelo predice un 75.10% de las veces que un cliente abandonará el banco. Sin embargo, hay que tomar en cuenta que no proporciona información sobre cuántos clientes que abandonan realmente el banco, el modelo no pudo identificar correctamente (falsos negativos).\n",
    "\n",
    "En recall obtuvimos un 0.4540, siendo un valor bastante bajo. Esta métrica indica que de todos los clientes que realmente abandonan el banco, el modelo pudo identificar correctamente el 45.41% de los clientes que realmente abandonaron el banco. Este dato hace en relación al valor de 214 (FN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, calculemos el valor de F1 y AUC-ROC, donde para que nuestro modelo sea aceptable, el valor de F1 debe ser de al menos 0.59. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor F1 en el conjunto de prueba: 0.5659777424483308\n",
      "Métrica AUC-ROC en el conjunto de prueba: 0.8292775599045588\n"
     ]
    }
   ],
   "source": [
    "# cálculo valor F1\n",
    "f1 = f1_score(target_test, predictions_test)\n",
    "\n",
    "# cálculo métrica AUC-ROC, probabilidades de la clase positiva (1) \n",
    "probabilities_test = model.predict_proba(features_test)[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_test)\n",
    "\n",
    "print(f\"Valor F1 en el conjunto de prueba: {f1}\")\n",
    "print(f\"Métrica AUC-ROC en el conjunto de prueba: {auc_roc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los valores obtenidos, el valor F1 combina tanto la precisión como el recall. Con un valor de 0.5659 indica que el modelo tiene un rendimiento moderado en términos de equilibrio entre los dos términos, sin embargo, no llegamos al valor mínimo que es 0.59, aunque estamos cerca, pero no es viable nuestro modelo. Esto se debe al desbalanceo de la clase objetivo. \n",
    "\n",
    "En cambio la métrica AUC-ROC toma en cuenta la distinción entre clases, en este caso, si un cliente abandona o no el banco. Un valor de AUC-ROC de 0.8292 en el conjunto de prueba indica el modelo tiene un buen rendimiento en términos de distinguir entre clientes que abandonan y no abandonan el banco, pero no es perfecto y aún hay margen de mejora. Esto se debe al valor de F1 que hay que mejorar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de modelo (clases balanceadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceo de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto que la implementación del modelo de árbol de decisión con clases desbalanceadas no logramos tener un *F1* mayor a 0.59, aunque estamos cerca ya que fue de 0.56. \n",
    "\n",
    "Por lo tanto, debemos balancear la clase objetivo para poder tener un mejor modelo que prediga de forma correcta si un cliente del banco va a dejar de ser cliente. \n",
    "\n",
    "Para hacer esto, se va a aplicar a los datos del banco el método de **oversampling**, el cual se enfoca en agregar más datos de la clase minoritaria mediante la duplicación de registros existentes o la generación de ejemplos sintéticos. Una forma de generar estos datos es a través de Synthetic Minority Over-sampling Technique (SMOTE) con la biblioteca `imbalanced-learn` y su función `SMOTE`.\n",
    "\n",
    "Por lo tanto, se balanceará los datos de entrenamiento. Se utiliza tanto `feature` y `target` que ya se asignó en la sección `4.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se divide primero en conjunto de entrenamiento_validacion y prueba\n",
    "features_train_val, features_test, target_train_val, target_test = train_test_split(features, target, test_size=0.2, random_state=4299)\n",
    "\n",
    "# luego, se divide el conjunto de entrenamiento_validacion en entrenamiento y validación\n",
    "features_train, features_val, target_train, target_val = train_test_split(features_train_val, target_train_val, test_size=0.25, random_state=4299)\n",
    "\n",
    "# se crea el objeto SMOTE y se aplica a los datos de entrenamiento\n",
    "smote = SMOTE(random_state=4299)\n",
    "features_train_resampled, target_train_resampled = smote.fit_resample(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación de equilibrio de clase objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo, con la implementación de `SMOTE` tenemos a `target_train_resampled` más balanceado. Verifiquemos cómo están los datos tanto de `0` y `1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidades de cada clase en target_train_resampled:\n",
      "0    4758\n",
      "1    4758\n",
      "Name: exited, dtype: int64\n",
      "\n",
      "Porcentajes de cada clase en target_train_resampled:\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cantidades y porcentajes de cada clase en target_train_resampled\n",
    "class_counts_resampled = target_train_resampled.value_counts()\n",
    "class_percentages_resampled = class_counts_resampled / len(target_train_resampled) * 100\n",
    "\n",
    "print(\"Cantidades de cada clase en target_train_resampled:\")\n",
    "print(class_counts_resampled)\n",
    "print(\"\\nPorcentajes de cada clase en target_train_resampled:\")\n",
    "print(class_percentages_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfecto, tenemos los datos balanceados entre 50% y 50%. Podemos proceder a implementar nuevamente el modelo del árbol de decisión a los datos de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de modelo en datos de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos correctamente los datos, podemos investigar qué modelo se ajusta mejor a nuestros datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Árbol de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificación de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos nuevamente el modelo del árbol de decisión. \n",
    "\n",
    "Se vuelve a utilizar el for loop para verificar qué hiperparámetro es mejor al momento de aplicar el modelo, con un `max_depth` de 50, pero también se incluirá los siguientes hiperparámetros para mejorar el rendimiento del modelo de árbol de decisión: \n",
    "- `min_samples_split` \n",
    "- `min_samples_leaf`\n",
    "- `max_features`\n",
    "- `max_leaf_nodes`\n",
    "\n",
    "De esta forma podremos saber qué hiperparámetro da el mejor `accuracy_score` para evaluar la precisión del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mejor puntuación de exactitud del conjunto de validación: 0.8435\n",
      "Mejores hiperparámetros encontrados:\n",
      "{'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': None, 'max_leaf_nodes': 100}\n"
     ]
    }
   ],
   "source": [
    "# hiperparámetros a considerar\n",
    "depth_range = range(1, 50)\n",
    "min_samples_split_range = [2, 5, 10]\n",
    "min_samples_leaf_range = [1, 2, 4]\n",
    "max_features_range = [None, 'sqrt', 'log2']\n",
    "max_leaf_nodes_range = [None, 10, 50, 100, 200]\n",
    "\n",
    "# variables iniciales\n",
    "best_result = 0\n",
    "best_params = {}\n",
    "\n",
    "# for loop para árbol de decisión con mejor hiperparámetro\n",
    "for depth, min_samples_split, min_samples_leaf, max_features, max_leaf_nodes in product(\n",
    "    depth_range, min_samples_split_range, min_samples_leaf_range, max_features_range, max_leaf_nodes_range):\n",
    "    \n",
    "    # aplicamos el modelo de árbol de decisión con distintos hiperparámetros\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "        random_state=4299)\n",
    "    \n",
    "    # entrenamos el modelo con el conjunto de entrenamiento\n",
    "    model.fit(features_train_resampled, target_train_resampled)\n",
    "    \n",
    "    # predicciones con el conjunto de validación\n",
    "    predictions_valid = model.predict(features_val)\n",
    "\n",
    "    # precisión\n",
    "    result = accuracy_score(target_val, predictions_valid)\n",
    "    \n",
    "    # mejor resultado e hiperparámetros\n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        best_params = {\n",
    "            'max_depth': depth,\n",
    "            'min_samples_split': min_samples_split,\n",
    "            'min_samples_leaf': min_samples_leaf,\n",
    "            'max_features': max_features,\n",
    "            'max_leaf_nodes': max_leaf_nodes,\n",
    "        }\n",
    "\n",
    "print(f\"La mejor puntuación de exactitud del conjunto de validación: {best_result}\")\n",
    "print(f\"Mejores hiperparámetros encontrados:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de Árbol de decisión llega a un umbral de exactitud de 0.8435 con los siguientes hiperparámetros: \n",
    "- `max_depth: 10`\n",
    "- `min_samples_split: 2`\n",
    "- `min_samples_leaf: 4`\n",
    "- `max_features: None`\n",
    "- `max_leaf_nodes: 100`\n",
    "\n",
    "Verifiquemos el modelo en los datos de prueba y viendo todas las métricas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementación datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementemos el modelo del árbol de decisión con los hiperparámetros definidos arriba, en los datos de prueba, calculando el `accuracy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de prueba en base a los hiperparámetros: 0.854\n"
     ]
    }
   ],
   "source": [
    "# entrenamos el modelo con el conjunto de entrenamiento y validación\n",
    "model = DecisionTreeClassifier(\n",
    "        max_depth=10,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=4,\n",
    "        max_features=None,\n",
    "        max_leaf_nodes=100,\n",
    "        random_state=4299)\n",
    "model.fit(features_train_val, target_train_val)\n",
    "\n",
    "# predecimos las etiquetas para el conjunto de prueba\n",
    "predictions_test = model.predict(features_test)\n",
    "\n",
    "# calculamos la precisión en el conjunto de prueba\n",
    "accuracy = accuracy_score(target_test, predictions_test)\n",
    "\n",
    "print(f\"Precisión en el conjunto de prueba en base a los hiperparámetros: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfecto, ahora que hemos entrenado el conjunto de prueba, y hemos obtenido una precisión de 0.854, apliquemos las métricas de rendimiento sobre el conjunto de prueba. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor F1 en el conjunto de prueba: 0.5780346820809249\n",
      "Área bajo la curva ROC (AUC-ROC) en el conjunto de prueba: 0.7240075134531424\n",
      "Precisión (precision) en el conjunto de prueba: 0.6666666666666666\n",
      "Sensibilidad (recall) en el conjunto de prueba: 0.5102040816326531\n",
      "Matriz de confusión en el conjunto de prueba:\n",
      "[[1508  100]\n",
      " [ 192  200]]\n"
     ]
    }
   ],
   "source": [
    "# cálculo de métricas de rendimiento para el conjunto de prueba\n",
    "accuracy = accuracy_score(target_test, predictions_test)\n",
    "f1 = f1_score(target_test, predictions_test)\n",
    "roc_auc = roc_auc_score(target_test, predictions_test)\n",
    "precision = precision_score(target_test, predictions_test)\n",
    "recall = recall_score(target_test, predictions_test)\n",
    "conf_matrix = confusion_matrix(target_test, predictions_test)\n",
    "\n",
    "# impresión de métricas de rendimiento\n",
    "print(f\"Valor F1 en el conjunto de prueba: {f1}\")\n",
    "print(f\"Área bajo la curva ROC (AUC-ROC) en el conjunto de prueba: {roc_auc}\")\n",
    "print(f\"Precisión (precision) en el conjunto de prueba: {precision}\")\n",
    "print(f\"Sensibilidad (recall) en el conjunto de prueba: {recall}\")\n",
    "print(\"Matriz de confusión en el conjunto de prueba:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según los resultados que se obtuvieron a continuación, el modelo del árbol de decisión con clases balanceadas mejoró un poco, pero aún no llegamos a un *F1* de 0.59, ya que obtuvimos un valor de 0.5780. \n",
    "\n",
    "El rendimiento del modelo es moderado, pero no alcanza aún al objetivo. De igual forma sigue siendo alto los falsos negativos, con un total de 192, lo cual se debería intentar disminuir.\n",
    "\n",
    "Necesitamos un modelo más robusto que prediga mejor, ya que aunque sin balancear los resultados de forma equitativa, cuando vengan nuevos datos, lo más probable es que la mayoría de clientes les va a clasificar como 0, es decir que no iba a dejar el banco cuando podría ser un posible cliente que si deje el banco (1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificación de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el modelo del árbol de decisión no logró un valor *F1* de 0.59, vamos a probar ahora con el modelo de Random Forest. Hay que tomar en cuenta que este modelo ya se implementará con la clase balanceada. \n",
    "\n",
    "De igual forma, vamos a probar con los datos de entrenamiento balanceados el modelo de Random Forest, identificando qué hiperparámetros dan la mejor puntuación de exactitud: \n",
    "- `n_estimators`\n",
    "- `max_depth`\n",
    "- `min_samples_split`\n",
    "- `min_samples_leaf`\n",
    "- `max_features`\n",
    "- `max_leaf_nodes`\n",
    "- `bootstrap`\n",
    "- `criterion`\n",
    "\n",
    "Para esto se utiliza `RandomizedSearchCV ` que es una clase en Scikit-learn que realiza una búsqueda aleatoria de hiperparámetros, utilizando validación cruzada. De esta forma definimos que máximo hará 200 corridas de forma aleatoria entre los distintos hiperparámetros, y así encontrar el mejor resultado, haciendo que nuestro código sea mucho más óptimo en cuestión de tiempo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mejor puntuación de exactitud del conjunto de validación: 0.8675914249684741\n",
      "Mejores hiperparámetros encontrados:\n",
      "{'n_estimators': 42, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 46, 'criterion': 'gini', 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# hiperparámetros a considerar\n",
    "param_dist = {\n",
    "    'n_estimators': range(1, 51),\n",
    "    'max_depth': range(1, 50),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes': [None, 10, 50, 100, 200],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# aplicamos el modelo de bosque aleatorio con distintos hiperparámetros\n",
    "model = RandomForestClassifier(random_state=4299)\n",
    "\n",
    "# número de iteraciones para la búsqueda aleatoria\n",
    "n_iter_search = 200\n",
    "\n",
    "# randomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_dist, n_iter=n_iter_search, cv=3, random_state=4299, n_jobs=-1)\n",
    "\n",
    "# entrenamos el modelo con el conjunto de entrenamiento\n",
    "random_search.fit(features_train_resampled, target_train_resampled)\n",
    "\n",
    "# mejores hiperparámetros encontrados\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# mejor puntuación de exactitud\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f\"La mejor puntuación de exactitud del conjunto de validación: {best_score}\")\n",
    "print(f\"Mejores hiperparámetros encontrados:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de RandomForest llega a un umbral de exactitud de 0.8622 con los siguientes hiperparámetros: \n",
    "- `n_estimators: 42`\n",
    "- `min_samples_split: 10`\n",
    "- `min_samples_leaf: 1`\n",
    "- `max_leaf_nodes: None`\n",
    "- `max_features: sqrt`\n",
    "- `max_depth: 46`\n",
    "- `criterion: gini`\n",
    "- `bootstrap: False`\n",
    "\n",
    "Verifiquemos el modelo en los datos de prueba y viendo todas las métricas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementación datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementemos el modelo de Random Forest con los hiperparámetros definidos arriba, calculando la precisión. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de prueba en base a los hiperparámetros: 0.8675\n"
     ]
    }
   ],
   "source": [
    "# entrenamos el modelo con el conjunto de entrenamiento y validación\n",
    "model = RandomForestClassifier(random_state=4299, \n",
    "                               n_estimators=42, \n",
    "                               min_samples_split=10, \n",
    "                               min_samples_leaf=1, \n",
    "                               max_leaf_nodes=None, \n",
    "                               max_features=\"sqrt\", \n",
    "                               max_depth=46, \n",
    "                               criterion=\"gini\", \n",
    "                               bootstrap=False)\n",
    "model.fit(features_train_val, target_train_val)\n",
    "\n",
    "# predecimos las etiquetas para el conjunto de prueba\n",
    "predictions_test = model.predict(features_test)\n",
    "\n",
    "# calculamos la precisión en el conjunto de prueba\n",
    "accuracy = accuracy_score(target_test, predictions_test)\n",
    "\n",
    "print(f\"Precisión en el conjunto de prueba en base a los hiperparámetros: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfecto, se obtuvo una precisión de 0.8675. Verifiquemos el resto de métricas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor F1 en el conjunto de prueba: 0.5966514459665145\n",
      "Área bajo la curva ROC (AUC-ROC) en el conjunto de prueba: 0.7285447761194029\n",
      "Precisión (precision) en el conjunto de prueba: 0.7396226415094339\n",
      "Sensibilidad (recall) en el conjunto de prueba: 0.5\n",
      "Matriz de confusión en el conjunto de prueba:\n",
      "[[1539   69]\n",
      " [ 196  196]]\n"
     ]
    }
   ],
   "source": [
    "# Calcular métricas de rendimiento para el conjunto de prueba\n",
    "accuracy = accuracy_score(target_test, predictions_test)\n",
    "f1 = f1_score(target_test, predictions_test)\n",
    "roc_auc = roc_auc_score(target_test, predictions_test)\n",
    "precision = precision_score(target_test, predictions_test)\n",
    "recall = recall_score(target_test, predictions_test)\n",
    "conf_matrix = confusion_matrix(target_test, predictions_test)\n",
    "\n",
    "# Imprimir métricas de rendimiento\n",
    "print(f\"Valor F1 en el conjunto de prueba: {f1}\")\n",
    "print(f\"Área bajo la curva ROC (AUC-ROC) en el conjunto de prueba: {roc_auc}\")\n",
    "print(f\"Precisión (precision) en el conjunto de prueba: {precision}\")\n",
    "print(f\"Sensibilidad (recall) en el conjunto de prueba: {recall}\")\n",
    "print(\"Matriz de confusión en el conjunto de prueba:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los resultados obtenidos, podemos observar que el modelo ha logrado un rendimiento satisfactorio y ha superado el umbral requerido de 0.59 en la métrica *F1*.\n",
    "\n",
    "A continuación, se presenta un resumen de las métricas de rendimiento del modelo:\n",
    "\n",
    "- Exactitud (accuracy): El modelo ha alcanzado una exactitud del 86.75%, lo que indica que ha clasificado correctamente el 86.75% de los casos en el conjunto de prueba.\n",
    "- Valor F1: El modelo ha logrado un valor F1 de 0.5967, superando el umbral mínimo de 0.59. Este valor indica que el modelo tiene un buen equilibrio entre precisión y sensibilidad.\n",
    "- Área bajo la curva ROC (AUC-ROC): El modelo tiene un AUC-ROC de 0.7285, lo que indica un buen rendimiento en la clasificación de las clases.\n",
    "- Precisión (precision): La precisión del modelo es del 73.96%, lo que muestra que, de todas las predicciones positivas realizadas por el modelo, el 73.96% de ellas son correctas.\n",
    "- Sensibilidad (recall): La sensibilidad del modelo es del 50%, lo que indica que ha identificado correctamente el 50% de los casos positivos reales en el conjunto de prueba.\n",
    "- La matriz de confusión muestra que el modelo ha clasificado correctamente 1539 casos negativos y 196 casos positivos, mientras que ha cometido errores en 69 casos negativos y 196 casos positivos.\n",
    "\n",
    "En general, el modelo ha logrado superar el umbral mínimo requerido en la métrica F1 y ha demostrado un buen rendimiento en las demás métricas. Sin embargo, siempre hay margen de mejora y podrías seguir ajustando los hiperparámetros o probar otros modelos para aumentar aún más el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conclusión, a lo largo de este proyecto, se llevaron a cabo varias etapas clave para mejorar el rendimiento del modelo de clasificación de la retención de clientes en un banco. Primero, se realizó una limpieza de datos donde se rellenaron los valores ausentes en la columna `Tenure`, para no perder datos valiosos y mantener la integridad de la información.\n",
    "\n",
    "Se implementó inicialmente un modelo de árbol de decisión con clases objetivo desbalanceadas (80% - 20%, 0 - 1), donde el valor 0 representa que el cliente no abandona el banco y el valor 1 representa que el cliente sí abandona el banco. En este caso, se obtuvo un valor *F1* de 0.56, lo que indica un rendimiento insuficiente.\n",
    "\n",
    "Para mejorar el rendimiento, se llevó a cabo un balanceo de la clase objetivo, ajustándola a una proporción de 50% - 50%. Luego, se implementaron modelos de árbol de decisión y bosque aleatorio (Random Forest) con distintos hiperparámetros para mejorar aún más los resultados.\n",
    "\n",
    "Finalmente, con el modelo de RandomForest y los siguientes hiperparámetros:\n",
    "- `n_estimators: 42`\n",
    "- `min_samples_split: 10`\n",
    "- `min_samples_leaf: 1`\n",
    "- `max_leaf_nodes: None`\n",
    "- `max_features: sqrt`\n",
    "- `max_depth: 46`\n",
    "- `criterion: gini`\n",
    "- `bootstrap: False`\n",
    "\n",
    "Se logró obtener un valor *F1* de 0.59, alcanzando el umbral mínimo requerido y demostrando un rendimiento satisfactorio en la clasificación de la retención de clientes en el banco.\n",
    "\n",
    "A pesar de haber alcanzado el umbral mínimo requerido, siempre hay espacio para mejorar y optimizar el rendimiento del modelo. Se pueden explorar y ajustar aún más los hiperparámetros o probar otros modelos de aprendizaje automático para obtener resultados más precisos en la predicción de la retención de clientes en el banco.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.194px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
